{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGiRHcU9dN1n",
        "outputId": "63bf105e-b630-40c4-c3e0-fda5ba8ed8d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnm4Iq-rcfY-",
        "outputId": "ce6541eb-0f74-45c7-97f5-08f7b5661577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a854c348450>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sys import argv\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(\n",
        "    model, tok, text,\n",
        "    do_sample=True, max_length=100, repetition_penalty=5.0,\n",
        "    top_k=5, top_p=0.95, temperature=1,\n",
        "    num_beams=None,\n",
        "    no_repeat_ngram_size=3\n",
        "):\n",
        "    input_ids = tok.encode(text, return_tensors=\"pt\")\n",
        "    out = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        do_sample=do_sample,\n",
        "        top_k=top_k, top_p=top_p, temperature=temperature,\n",
        "        num_beams=num_beams, no_repeat_ngram_size=no_repeat_ngram_size\n",
        "    )\n",
        "    return list(map(tok.decode, out))"
      ],
      "metadata": {
        "id": "LBO6M8ioeL32"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка\n",
        "def load_tokenizer_and_model(model_name_or_path):\n",
        "    return GPT2Tokenizer.from_pretrained(model_name_or_path), GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
        ""
      ],
      "metadata": {
        "id": "WFy4LESWdmqg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cлова для работы \"значит\" и \"помощь\"."
      ],
      "metadata": {
        "id": "mHLGqWp7etWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск\n",
        "tok, model = load_tokenizer_and_model(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n",
        "generated = generate(model, tok, \"Держа в руках замерзшего щенка, я плакал. Любить животных бывает так невыносимо больно. Если это не ваш питомец, это не\", num_beams=10)\n",
        "print(generated[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf64U8GvdmzZ",
        "outputId": "c78015b8-60b7-4d00-a26a-4b2720edbcc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Держа в руках замерзшего щенка, я плакал. Любить животных бывает так невыносимо больно. Если это не ваш питомец, это не значит, что он вам не нужен.\n",
            "\n",
            "— Я люблю собак, — всхлипывая, сказал я. — Но у меня нет времени на то, чтобы заниматься их воспитанием и дрессировкой. У меня есть дела поважнее. Я должен найти человека, который мог бы мне помочь. Мне нужна ваша помощь. Вы поможете?\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}