# -*- coding: utf-8 -*-
"""NLP_Laba_3_Zemlyanova.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U0t0OJCLhke24az1XitKMKtawVvB5obw

#**Практическая работа «Анализ на основе RNN»**

***Землянова Анна Группа 932001***

*Задание:*

Необходимо провести повторный анализ текста, который использовался в работе «Предобработка текста », но с использованием import rnnmorph и без использования import pymorphy2.

Если полученные результаты различаются, необходимо пояснить, почему так вышло.
"""

pip install rnnmorph

import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')
import re

# Импортируем RNNMorphPredictor и создаем экземпляр:
from rnnmorph.predictor import RNNMorphPredictor
predictor = RNNMorphPredictor(language='ru')

def parse_morph_tags(tag_str):
    # Если строка пуста, возвращаем значения "Null" для всех атрибутов
    if tag_str == '_':
        return {'Case': 'Null', 'Gender': 'Null', 'Number': 'Null'}

    # Разделяем строку тегов по символу "|"
    tag_parts = tag_str.split('|')

    tag_dict = {}
    # Разбираем каждую часть тега и добавляем в словарь
    for part in tag_parts:
        key, value = part.split('=')
        tag_dict[key] = value

    return tag_dict

# Прочитаем текст из файла
with open('Text.txt', 'r', encoding='utf-8') as file:
    text = file.read()

    print("Текст до:")
    print(text)

# разбиваем текст на предложения
sentences = re.split(r'(?<=[.!?])\s+', text)

#print(sentences)

lem_and_tag = []

for sentence in sentences:
     words = word_tokenize(sentence)
     #print("\n", words)
     analyzed_words = predictor.predict(words)
     lem_and_tag.extend([(word.pos, word.normal_form, word.tag) for word in analyzed_words])

# Найдем пары соседних слов, удовлетворяющие условиям (совпадают по роду, числу и падежу):

match_pairs = []

for i in range(len(lem_and_tag) - 1):
    pos1, word1, tag1 = lem_and_tag[i]
    pos2, word2, tag2 = lem_and_tag[i + 1]

    tag1_values = tag1.split('|')
    tag2_values = tag2.split('|')

    #print("tag1_values :", tag1_values )
    #print("tag2_values :", tag2_values, "\n")

    tag1_dict = parse_morph_tags(tag1)
    tag2_dict = parse_morph_tags(tag2)

    if 'NOUN' in pos1 or 'NOUN' in pos2:
        if 'ADJ' in pos1 or 'ADJ' in pos2:
            if tag1_dict['Case']  == tag2_dict['Case']  and tag1_dict['Number'] == tag2_dict['Number'] and tag1_dict['Gender'] == tag2_dict['Gender']:
                match_pairs.append((word1, word2))
                #print(word1, word2)

# Выводим найденные пары:
for pair in match_pairs:
    print(pair[0], pair[1])