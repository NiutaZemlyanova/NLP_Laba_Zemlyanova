{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Практическая работа «Предобработка текста »**\n",
        "\n",
        "***Землянова Анна Группа 932001***\n",
        "\n",
        "*Задание:*\n",
        "\n",
        "Требуется прочитать текст на русском языке из файла и вывести все пары соседних слов, которые:\n",
        "имеют имена существительные или имена прилагательные на первом или втором месте;совпадают по роду, числу и падежу.\n",
        "\n",
        "Все пары следует выводить в виде лемм. Например, если исходная пара имела вид «необычайных университетов», то должна быть выведена пара «необычайный университет»."
      ],
      "metadata": {
        "id": "tNc3X-dDltHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUws3soGnnVX",
        "outputId": "3932e4f6-e11c-4e6c-a27b-ddbf68dd1bf3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизация\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') # Загружаем необходимые ресурсы для NLTK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HEDIO1UrOVR",
        "outputId": "c086eaa3-a574-4455-e1ea-389f027a229f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сегментация\n",
        "import nltk\n",
        "from nltk import sent_tokenize"
      ],
      "metadata": {
        "id": "W5ru97tBrOE3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Лемматизация\n",
        "# И получение грамматических атрибутов\n",
        "import pymorphy2\n",
        "m = pymorphy2.MorphAnalyzer() # Создаем экземпляр анализатора pymorphy2"
      ],
      "metadata": {
        "id": "N1PZz7YwrWAM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка на то, является ли слово сущ или прил\n",
        "def is_noun_or_adj(word):\n",
        "    parsed_word = m.parse(word)[0]\n",
        "    return 'NOUN' in parsed_word.tag or 'ADJF' in parsed_word.tag"
      ],
      "metadata": {
        "id": "tyPxa0M4sMcu"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Совпадают ли слова по роду, числу и падежу\n",
        "def match_pairs(word1, word2):\n",
        "# Лемматизируем слова\n",
        "    parsed_word1 = m.parse(word1)[0]\n",
        "    parsed_word2 = m.parse(word2)[0]\n",
        "\n",
        "# Проверяем, совпадают ли слова по роду, числу и падежу\n",
        "    if 'NOUN' in parsed_word1.tag or 'NOUN' in parsed_word2.tag:\n",
        "        if parsed_word1.tag.gender == parsed_word2.tag.gender and parsed_word1.tag.number == parsed_word2.tag.number and parsed_word1.tag.case == parsed_word2.tag.case:\n",
        "            return True\n",
        "    elif 'ADJF' in parsed_word1.tag or 'ADJF' in parsed_word2.tag:\n",
        "        if parsed_word1.tag.gender == parsed_word2.tag.gender and parsed_word1.tag.number == parsed_word2.tag.number and parsed_word1.tag.case == parsed_word2.tag.case:\n",
        "            return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "T1twZq_grLXr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Прочитаем текст из файла (замените 'input.txt' на путь к вашему файлу)\n",
        "with open('Text.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "    print(\"Текст до:\")\n",
        "    print(text)\n",
        "\n",
        "# Найдем и выведем пары\n",
        "    ### print(\"Разбиваем текст на предложения:\")\n",
        "    sentences = sent_tokenize(text) # Разбиваем текст на предложения\n",
        "    ### print(sentences)\n",
        "\n",
        "    print(\"\\nПары слов, удовлетворяющие условиям:\")\n",
        "\n",
        "    for sentence in sentences:\n",
        "# Токенизируем предложение на слова\n",
        "\n",
        "        ### print(\"\\nТокенизируем предложение на слова:\")\n",
        "        words = word_tokenize(sentence)\n",
        "        ### print(words, \"\\n\")\n",
        "\n",
        "        # Проходим по словам и ищем пары, удовлетворяюще условиям\n",
        "        for i in range(len(words) - 1):\n",
        "            word1 = words[i]\n",
        "            word2 = words[i + 1]\n",
        "\n",
        "            if is_noun_or_adj(word1) and is_noun_or_adj(word2) and match_pairs(word1, word2):\n",
        "              W1 = m.parse(word1)[0].normal_form\n",
        "              W2 = m.parse(word2)[0].normal_form\n",
        "              print(\" \",W1, W2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvZ0uDnpshGX",
        "outputId": "61741df9-d438-4dde-d52c-a2234ed45f29"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст до:\n",
            "Маленький кот и большая собака пошли гулять в парк. Черный кот и белая собака бегали весело по зеленой траве. Маленькая девочка кормила кота и собаку. Счастливая девочка улыбалась.\n",
            "\n",
            "Пары слов, удовлетворяющие условиям:\n",
            "  маленький кот\n",
            "  больший собака\n",
            "  чёрный кот\n",
            "  белый собака\n",
            "  маленький девочка\n",
            "  счастливый девочка\n"
          ]
        }
      ]
    }
  ]
}